{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect and trim images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/ears/annotations/recognition/ids.csv', names=['filename', 'label'])\n",
    "df['label'] = df['label'].astype(str)\n",
    "train_labels=df[df['filename'].str.startswith('train')]['label'].to_numpy()\n",
    "test_labels=df[df['filename'].str.startswith('test')]['label'].to_numpy()\n",
    "df_train = df[df['filename'].str.startswith('train')]\n",
    "df_test = df[df['filename'].str.startswith('test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2021-12-12 torch 1.10.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 270 layers, 7022326 parameters, 0 gradients, 15.8 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>> Processing:  train 0001.png\n",
      "image 1/1 D:\\FRI\\Magisterij\\SB\\Assignment 3\\Faces - Keras\\data\\ears_yolo\\images\\train_hist_gauss\\0001.png: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2021-12-12 torch 1.10.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 270 layers, 7022326 parameters, 0 gradients, 15.8 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480x640 1 ear, Done. (0.132s)\n",
      "Speed: 0.0ms pre-process, 132.0ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp1622\u001b[0m\n",
      "1 labels saved to runs\\detect\\exp1622\\labels\n",
      "Writing result to: data_cnn_test/ears/train\\0001.png\n",
      ">>>>>>>>>>>>>> Processing:  train 0002.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-fb771a909ffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[0mev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrimImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m \u001b[0mev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-fb771a909ffa>\u001b[0m in \u001b[0;36mrun_trim\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[1;31m# prediction_list = cascade_detector.detect(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                 \u001b[0mprediction_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'results/hist_gauss_4_best.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mim_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnosave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_txt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;31m# Read annotations:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yolov5\\detect.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(weights, source, imgsz, conf_thres, iou_thres, max_det, device, view_img, save_txt, save_conf, save_crop, nosave, classes, agnostic_nms, augment, visualize, update, project, name, exist_ok, line_thickness, hide_labels, hide_conf, half, dnn)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# run once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim0s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvid_cap\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_sync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0monnx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yolov5\\utils\\datasets.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;31m# Read image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[0mimg0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# BGR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mimg0\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Image Not Found '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'image {self.count}/{self.nf} {path}: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "class TrimImages:\n",
    "\n",
    "\n",
    "    def get_annotations(self, annot_name):\n",
    "            with open(annot_name) as f:\n",
    "                lines = f.readlines()\n",
    "                annot = []\n",
    "                for line in lines:\n",
    "                    l_arr = line.split(\" \")[1:5]\n",
    "                    l_arr = [float(i) for i in l_arr]\n",
    "                    annot.append(l_arr)\n",
    "            return annot\n",
    "    def run_trim(self):\n",
    "\n",
    "        from yolov5 import detect\n",
    "        results = []\n",
    "        for src_type in ['train', 'test']:\n",
    "            count = 0\n",
    "            trim_src = f'data/ears_yolo/images/{src_type}_hist_gauss'\n",
    "            trim_target = f'data_cnn_test/ears/{src_type}'\n",
    "            im_list = sorted(glob.glob(trim_src + '/*.png', recursive=True))\n",
    "            for im_name in im_list:\n",
    "                # Read an image\n",
    "                img = cv2.imread(im_name)\n",
    "                filename = os.path.basename(im_name)\n",
    "                print('>>>>>>>>>>>>>> Processing: ', src_type, filename)\n",
    "\n",
    "                # Apply some preprocessing\n",
    "                # img = preprocess.histogram_equlization_rgb(img) # This one makes VJ worse\n",
    "                \n",
    "                # Run the detector. It runs a list of all the detected bounding-boxes. In segmentor you only get a mask matrices, but use the iou_compute in the same way.\n",
    "                # prediction_list = cascade_detector.detect(img)\n",
    "                \n",
    "                prediction_list = detect.run(weights='results/hist_gauss_4_best.pt', source=im_name, nosave=True, save_txt=True)\n",
    "\n",
    "                # Read annotations:\n",
    "                prediction_last = glob.glob('runs/detect/*', recursive=True)\n",
    "                prediction_last.sort(key=os.path.getmtime)\n",
    "                prediction_name = os.path.join(prediction_last.pop(), 'labels', Path(os.path.basename(im_name)).stem) + '.txt'\n",
    "                prediction_list = []\n",
    "                if (os.path.exists(prediction_name)):\n",
    "                    prediction_list = self.get_annotations(prediction_name)\n",
    "\n",
    "                # print(prediction_list, annot_list)\n",
    "                x = len(img[0])\n",
    "                y = len(img)\n",
    "\n",
    "                prediction_list_2 = []\n",
    "                for item in prediction_list:\n",
    "                    prediction_list_2.append([int(item[0] * x), int(item[1] * y), int(item[2] * x), int(item[3] * y)])\n",
    "                \n",
    "                prediction_list_2 = prediction_list_2[0]\n",
    "                center_x = prediction_list_2[0]\n",
    "                center_y = prediction_list_2[1]\n",
    "                width = prediction_list_2[2]\n",
    "                height = prediction_list_2[3]\n",
    "                # if (width == 0 or height == 0):\n",
    "                #     continue\n",
    "                x_start = center_x - (width // 2)\n",
    "                y_start = center_y - (height // 2)\n",
    "                x_end = center_x + (width // 2)\n",
    "                y_end = center_y + (height // 2)\n",
    "                trimmed_img = img[y_start:y_end, x_start:x_end]\n",
    "                if (len(trimmed_img) == 0):\n",
    "                    continue\n",
    "                # cv2.imshow('trim', trimmed_img)\n",
    "                # cv2.waitKey(0)\n",
    "                # break\n",
    "                print(\"Writing result to: \"+ os.path.join(trim_target, filename))\n",
    "                cv2.imwrite(os.path.join(trim_target, filename), trimmed_img)\n",
    "                count = count + 1\n",
    "            text = f\"Detection success for '{src_type}': {count}/{len(im_list)}\"\n",
    "            results.append(text)\n",
    "            print(text)\n",
    "        print(results)\n",
    "            \n",
    "            \n",
    "\n",
    "ev = TrimImages()\n",
    "ev.run_trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to torch file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train            filename label\n",
      "632  train/0383.png    56\n",
      "657  train/0408.png    59\n",
      "485  train/0236.png    39\n",
      "706  train/0457.png    65\n",
      "459  train/0210.png    36\n",
      "..              ...   ...\n",
      "321  train/0072.png    19\n",
      "356  train/0107.png    23\n",
      "520  train/0271.png    43\n",
      "685  train/0436.png    63\n",
      "352  train/0103.png    23\n",
      "\n",
      "[525 rows x 2 columns]\n",
      "val            filename label\n",
      "756  train/0507.png    71\n",
      "607  train/0358.png    53\n",
      "383  train/0134.png    27\n",
      "500  train/0251.png    41\n",
      "549  train/0300.png     5\n",
      "..              ...   ...\n",
      "432  train/0183.png    32\n",
      "819  train/0570.png    79\n",
      "514  train/0265.png    42\n",
      "998  train/0749.png     7\n",
      "473  train/0224.png    37\n",
      "\n",
      "[225 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "source_dir = 'data_cnn/ears'\n",
    "target_dir = 'data_torch'\n",
    "df = pd.read_csv('data_cnn/ears/annotations/recognition/ids.csv', names=['filename', 'label'])\n",
    "df['label'] = df['label'].astype(str)\n",
    "train_labels=df[df['filename'].str.startswith('train')]['label'].to_numpy()\n",
    "test_labels=df[df['filename'].str.startswith('test')]['label'].to_numpy()\n",
    "df_train = df[df['filename'].str.startswith('train')]\n",
    "df_test = df[df['filename'].str.startswith('test')]\n",
    "\n",
    "train_len = int(0.7*len(df_train))\n",
    "valid_len = len(df_train) - train_len\n",
    "train, val = train_test_split(df_train, test_size=0.3, random_state=42, shuffle=True)\n",
    "print(\"train\", train)\n",
    "print(\"val\", val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0001.png\n",
      "Processing: 0002.png\n",
      "Processing: 0003.png\n",
      "Processing: 0004.png\n",
      "Processing: 0005.png\n",
      "Processing: 0006.png\n",
      "Processing: 0007.png\n",
      "Processing: 0008.png\n",
      "Processing: 0009.png\n",
      "Processing: 0010.png\n",
      "Processing: 0011.png\n",
      "Processing: 0012.png\n",
      "Processing: 0013.png\n",
      "Processing: 0014.png\n",
      "Processing: 0015.png\n",
      "Processing: 0016.png\n",
      "Processing: 0017.png\n",
      "Processing: 0018.png\n",
      "Processing: 0019.png\n",
      "Processing: 0020.png\n",
      "Processing: 0021.png\n",
      "Processing: 0022.png\n",
      "Processing: 0023.png\n",
      "Processing: 0024.png\n",
      "Processing: 0025.png\n",
      "Processing: 0026.png\n",
      "Processing: 0027.png\n",
      "Processing: 0028.png\n",
      "Processing: 0029.png\n",
      "Processing: 0030.png\n",
      "Processing: 0031.png\n",
      "Processing: 0032.png\n",
      "Processing: 0033.png\n",
      "Processing: 0034.png\n",
      "Processing: 0035.png\n",
      "Processing: 0036.png\n",
      "Processing: 0037.png\n",
      "Processing: 0038.png\n",
      "Processing: 0039.png\n",
      "Processing: 0040.png\n",
      "Processing: 0041.png\n",
      "Processing: 0042.png\n",
      "Processing: 0043.png\n",
      "Processing: 0044.png\n",
      "Processing: 0045.png\n",
      "Processing: 0046.png\n",
      "Processing: 0047.png\n",
      "Processing: 0048.png\n",
      "Processing: 0049.png\n",
      "Processing: 0050.png\n",
      "Processing: 0051.png\n",
      "Processing: 0052.png\n",
      "Processing: 0053.png\n",
      "Processing: 0054.png\n",
      "Processing: 0055.png\n",
      "Processing: 0056.png\n",
      "Processing: 0057.png\n",
      "Processing: 0058.png\n",
      "Processing: 0059.png\n",
      "Processing: 0060.png\n",
      "Processing: 0061.png\n",
      "Processing: 0062.png\n",
      "Processing: 0063.png\n",
      "Processing: 0064.png\n",
      "Processing: 0065.png\n",
      "Processing: 0066.png\n",
      "Processing: 0067.png\n",
      "Processing: 0068.png\n",
      "Processing: 0069.png\n",
      "Processing: 0070.png\n",
      "Processing: 0071.png\n",
      "Processing: 0072.png\n",
      "Processing: 0073.png\n",
      "Processing: 0074.png\n",
      "Processing: 0075.png\n",
      "Processing: 0076.png\n",
      "Processing: 0077.png\n",
      "Processing: 0078.png\n",
      "Processing: 0079.png\n",
      "Processing: 0080.png\n",
      "Processing: 0081.png\n",
      "Processing: 0082.png\n",
      "Processing: 0083.png\n",
      "Processing: 0084.png\n",
      "Processing: 0085.png\n",
      "Processing: 0086.png\n",
      "Processing: 0087.png\n",
      "Processing: 0088.png\n",
      "Processing: 0089.png\n",
      "Processing: 0090.png\n",
      "Processing: 0091.png\n",
      "Processing: 0092.png\n",
      "Processing: 0093.png\n",
      "Processing: 0094.png\n",
      "Processing: 0095.png\n",
      "Processing: 0096.png\n",
      "Processing: 0097.png\n",
      "Processing: 0098.png\n",
      "Processing: 0099.png\n",
      "Processing: 0100.png\n",
      "Processing: 0101.png\n",
      "Processing: 0102.png\n",
      "Processing: 0103.png\n",
      "Processing: 0104.png\n",
      "Processing: 0105.png\n",
      "Processing: 0106.png\n",
      "Processing: 0107.png\n",
      "Processing: 0108.png\n",
      "Processing: 0109.png\n",
      "Processing: 0110.png\n",
      "Processing: 0111.png\n",
      "Processing: 0112.png\n",
      "Processing: 0113.png\n",
      "Processing: 0114.png\n",
      "Processing: 0115.png\n",
      "Processing: 0116.png\n",
      "Processing: 0117.png\n",
      "Processing: 0118.png\n",
      "Processing: 0119.png\n",
      "Processing: 0120.png\n",
      "Processing: 0121.png\n",
      "Processing: 0122.png\n",
      "Processing: 0123.png\n",
      "Processing: 0124.png\n",
      "Processing: 0125.png\n",
      "Processing: 0126.png\n",
      "Processing: 0127.png\n",
      "Processing: 0128.png\n",
      "Processing: 0129.png\n",
      "Processing: 0130.png\n",
      "Processing: 0131.png\n",
      "Processing: 0132.png\n",
      "Processing: 0133.png\n",
      "Processing: 0134.png\n",
      "Processing: 0135.png\n",
      "Processing: 0136.png\n",
      "Processing: 0137.png\n",
      "Processing: 0138.png\n",
      "Processing: 0139.png\n",
      "Processing: 0140.png\n",
      "Processing: 0141.png\n",
      "Processing: 0142.png\n",
      "Processing: 0143.png\n",
      "Processing: 0144.png\n",
      "Processing: 0145.png\n",
      "Processing: 0146.png\n",
      "Processing: 0147.png\n",
      "Processing: 0148.png\n",
      "Processing: 0149.png\n",
      "Processing: 0150.png\n",
      "Processing: 0151.png\n",
      "Processing: 0152.png\n",
      "Processing: 0153.png\n",
      "Processing: 0154.png\n",
      "Processing: 0155.png\n",
      "Processing: 0156.png\n",
      "Processing: 0157.png\n",
      "Processing: 0158.png\n",
      "Processing: 0159.png\n",
      "Processing: 0160.png\n",
      "Processing: 0161.png\n",
      "Processing: 0162.png\n",
      "Processing: 0163.png\n",
      "Processing: 0164.png\n",
      "Processing: 0165.png\n",
      "Processing: 0166.png\n",
      "Processing: 0167.png\n",
      "Processing: 0168.png\n",
      "Processing: 0169.png\n",
      "Processing: 0170.png\n",
      "Processing: 0171.png\n",
      "Processing: 0172.png\n",
      "Processing: 0173.png\n",
      "Processing: 0174.png\n",
      "Processing: 0175.png\n",
      "Processing: 0176.png\n",
      "Processing: 0177.png\n",
      "Processing: 0178.png\n",
      "Processing: 0179.png\n",
      "Processing: 0180.png\n",
      "Processing: 0181.png\n",
      "Processing: 0182.png\n",
      "Processing: 0183.png\n",
      "Processing: 0184.png\n",
      "Processing: 0185.png\n",
      "Processing: 0186.png\n",
      "Processing: 0187.png\n",
      "Processing: 0188.png\n",
      "Processing: 0189.png\n",
      "Processing: 0190.png\n",
      "Processing: 0191.png\n",
      "Processing: 0192.png\n",
      "Processing: 0193.png\n",
      "Processing: 0194.png\n",
      "Processing: 0195.png\n",
      "Processing: 0196.png\n",
      "Processing: 0197.png\n",
      "Processing: 0198.png\n",
      "Processing: 0199.png\n",
      "Processing: 0200.png\n",
      "Processing: 0201.png\n",
      "Processing: 0202.png\n",
      "Processing: 0203.png\n",
      "Processing: 0204.png\n",
      "Processing: 0205.png\n",
      "Processing: 0206.png\n",
      "Processing: 0207.png\n",
      "Processing: 0208.png\n",
      "Processing: 0209.png\n",
      "Processing: 0210.png\n",
      "Processing: 0211.png\n",
      "Processing: 0212.png\n",
      "Processing: 0213.png\n",
      "Processing: 0214.png\n",
      "Processing: 0215.png\n",
      "Processing: 0216.png\n",
      "Processing: 0217.png\n",
      "Processing: 0218.png\n",
      "Processing: 0219.png\n",
      "Processing: 0220.png\n",
      "Processing: 0221.png\n",
      "Processing: 0222.png\n",
      "Processing: 0223.png\n",
      "Processing: 0224.png\n",
      "Processing: 0225.png\n",
      "Processing: 0226.png\n",
      "Processing: 0227.png\n",
      "Processing: 0228.png\n",
      "Processing: 0229.png\n",
      "Processing: 0230.png\n",
      "Processing: 0231.png\n",
      "Processing: 0232.png\n",
      "Processing: 0233.png\n",
      "Processing: 0234.png\n",
      "Processing: 0235.png\n",
      "Processing: 0236.png\n",
      "Processing: 0237.png\n",
      "Processing: 0238.png\n",
      "Processing: 0239.png\n",
      "Processing: 0240.png\n",
      "Processing: 0241.png\n",
      "Processing: 0242.png\n",
      "Processing: 0243.png\n",
      "Processing: 0244.png\n",
      "Processing: 0245.png\n",
      "Processing: 0246.png\n",
      "Processing: 0247.png\n",
      "Processing: 0248.png\n",
      "Processing: 0249.png\n",
      "Processing: 0250.png\n"
     ]
    }
   ],
   "source": [
    "for index, row in train.iterrows():\n",
    "    filename = row['filename'].split(\"/\")[-1]\n",
    "    print(\"Processing: \"+ row['filename'])\n",
    "    if (not os.path.exists(os.path.join(target_dir, 'test', row['label']))):\n",
    "        os.mkdir(os.path.join(target_dir, 'val', row['label']))\n",
    "\n",
    "    src_file = os.path.join(source_dir, row['filename'])\n",
    "    trgt_file = os.path.join(target_dir, 'train', row['label'], filename)\n",
    "    copyfile(src_file, trgt_file)\n",
    "\n",
    "for index, row in val.iterrows():\n",
    "    filename = row['filename'].split(\"/\")[-1]\n",
    "    print(\"Processing: \"+ row['filename'])\n",
    "    if (not os.path.exists(os.path.join(target_dir, 'test', row['label']))):\n",
    "        os.mkdir(os.path.join(target_dir, 'val', row['label']))\n",
    "\n",
    "    src_file = os.path.join(source_dir, row['filename'])\n",
    "    trgt_file = os.path.join(target_dir, 'val', row['label'], filename)\n",
    "    copyfile(src_file, trgt_file)\n",
    "    \n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    filename = row['filename'].split(\"/\")[-1]\n",
    "    print(\"Processing: \"+ row['filename'])\n",
    "    if (not os.path.exists(os.path.join(target_dir, 'test', row['label']))):\n",
    "        os.mkdir(os.path.join(target_dir, 'test', row['label']))\n",
    "\n",
    "    src_file = os.path.join(source_dir, row['filename'])\n",
    "    trgt_file = os.path.join(target_dir, 'test', row['label'], filename)\n",
    "    copyfile(src_file, trgt_file)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78010e648cab4d2ba8c0f9090d51258d09f88d036db090ce2c604fe3a9dbf2ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
